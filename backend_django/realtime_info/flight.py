import asyncio
import json
from datetime import datetime, timedelta
from playwright.async_api import async_playwright
import pandas as pd
import time

class NaverFlightCrawler:
    def __init__(self):
        self.base_url = "https://flight.naver.com/flights/"
        self.countries = {
            'italy': ['FCO', 'MXP', 'NAP'],  # ë¡œë§ˆ, ë°€ë¼ë…¸, ë‚˜í´ë¦¬
            'japan': ['NRT', 'HND', 'KIX', 'NGO'],  # ë‚˜ë¦¬íƒ€, í•˜ë„¤ë‹¤, ê°„ì‚¬ì´, ì¤‘ë¶€
            'singapore': ['SIN'],  # ì‹±ê°€í¬ë¥´
            'uk': ['LHR', 'LGW', 'STN'],  # íˆë“œë¡œ, ê°œíŠ¸ìœ…, ìŠ¤íƒ ìŠ¤í…Œë“œ
            'australia': ['SYD', 'MEL', 'BNE'],  # ì‹œë“œë‹ˆ, ë©œë²„ë¥¸, ë¸Œë¦¬ì¦ˆë²ˆ
            'austria': ['VIE'],  # ë¹„ì—”ë‚˜
            'canada': ['YVR', 'YYZ'],  # ë°´ì¿ ë²„, í† ë¡ í† 
            'america': ['LAX', 'JFK', 'SFO', 'ORD'],  # LA, ë‰´ìš•, ìƒŒí”„ë€ì‹œìŠ¤ì½”, ì‹œì¹´ê³ 
            'china': ['PEK', 'PVG', 'CAN'],  # ë² ì´ì§•, ìƒí•˜ì´, ê´‘ì €ìš°
            'france': ['CDG', 'ORY'],  # ìƒ¤ë¥¼ë“œê³¨, ì˜¤ë¥¼ë¦¬
            'germany': ['FRA', 'MUC'],  # í”„ë‘í¬í‘¸ë¥´íŠ¸, ë®Œí—¨
            'newzealand': ['AKL', 'CHC']  # ì˜¤í´ëœë“œ, í¬ë¼ì´ìŠ¤íŠ¸ì²˜ì¹˜
        }
        
        # ê³µí•­ ì½”ë“œë³„ ë„ì‹œëª… ë§¤í•‘
        self.airport_cities = {
            'FCO': 'ë¡œë§ˆ', 'MXP': 'ë°€ë¼ë…¸', 'NAP': 'ë‚˜í´ë¦¬',
            'NRT': 'ë„ì¿„(ë‚˜ë¦¬íƒ€)', 'HND': 'ë„ì¿„(í•˜ë„¤ë‹¤)', 'KIX': 'ì˜¤ì‚¬ì¹´', 'NGO': 'ë‚˜ê³ ì•¼',
            'SIN': 'ì‹±ê°€í¬ë¥´',
            'LHR': 'ëŸ°ë˜(íˆë“œë¡œ)', 'LGW': 'ëŸ°ë˜(ê°œíŠ¸ìœ…)', 'STN': 'ëŸ°ë˜(ìŠ¤íƒ ìŠ¤í…Œë“œ)',
            'SYD': 'ì‹œë“œë‹ˆ', 'MEL': 'ë©œë²„ë¥¸', 'BNE': 'ë¸Œë¦¬ì¦ˆë²ˆ',
            'VIE': 'ë¹„ì—”ë‚˜',
            'YVR': 'ë°´ì¿ ë²„', 'YYZ': 'í† ë¡ í† ',
            'LAX': 'ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤', 'JFK': 'ë‰´ìš•', 'SFO': 'ìƒŒí”„ë€ì‹œìŠ¤ì½”', 'ORD': 'ì‹œì¹´ê³ ',
            'PEK': 'ë² ì´ì§•', 'PVG': 'ìƒí•˜ì´', 'CAN': 'ê´‘ì €ìš°',
            'CDG': 'íŒŒë¦¬(ìƒ¤ë¥¼ë“œê³¨)', 'ORY': 'íŒŒë¦¬(ì˜¤ë¥¼ë¦¬)',
            'FRA': 'í”„ë‘í¬í‘¸ë¥´íŠ¸', 'MUC': 'ë®Œí—¨',
            'AKL': 'ì˜¤í´ëœë“œ', 'CHC': 'í¬ë¼ì´ìŠ¤íŠ¸ì²˜ì¹˜'
        }
        
    async def setup_browser(self):
        """ë¸Œë¼ìš°ì € ì´ˆê¸°í™”"""
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=False,  # í¬ë¡¤ë§ ê³¼ì •ì„ ë³´ë ¤ë©´ False
            args=['--no-sandbox', '--disable-dev-shm-usage']
        )
        self.context = await self.browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36"
        )
        self.page = await self.context.new_page()
        
    async def close_browser(self):
        """ë¸Œë¼ìš°ì € ì •ë¦¬"""
        await self.browser.close()
        await self.playwright.stop()
        
    async def search_flights(self, departure='ICN', arrival='NRT', date=None):
        """í•­ê³µí¸ ê²€ìƒ‰"""
        try:
            # ë„¤ì´ë²„ í•­ê³µ ì‚¬ì´íŠ¸ ì ‘ì†
            await self.page.goto("https://flight.naver.com/flights/international/ICN-DAD-20250707?adult=1&isDirect=true&fareType=Y", wait_until='domcontentloaded')
            await self.page.wait_for_timeout(5000)  # ë” ê¸´ ëŒ€ê¸°ì‹œê°„
            
        except Exception as e:
            print(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    async def extract_flight_data(self):
        """í•­ê³µí¸ ë°ì´í„° ì¶”ì¶œ"""
        flights = []
        
        try:
            # í˜ì´ì§€ URL í™•ì¸ (ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™í–ˆëŠ”ì§€ í™•ì¸)
            current_url = self.page.url
            print(f"í˜„ì¬ í˜ì´ì§€ URL: {current_url}")
            
            items = await self.page.query_selector_all('.indivisual_IndivisualItem__CVm69.indivisual_with_labels__vj6Hn')
            
            # í•­ê³µí¸ ë°ì´í„° ì¶”ì¶œ
            for i, item in enumerate(items[:3]):  # ìµœëŒ€ 15ê°œ ê²°ê³¼ë§Œ
                try:
                    # í•­ê³µì‚¬ëª… ì¶”ì¶œ
                    airline_selectors = [
                        '[class*="airline"]', '[class*="company"]', '[class*="carrier"]',
                        '[class*="name"]', '.airline', '.company'
                    ]
                    airline = "ì •ë³´ì—†ìŒ"
                    for selector in airline_selectors:
                        try:
                            airline_elem = await item.query_selector(selector)
                            if airline_elem:
                                text = await airline_elem.inner_text()
                                if text and text.strip():
                                    airline = text.strip()
                                    break
                        except:
                            continue
                    
                    # ê°€ê²© ì¶”ì¶œ (ê°€ì¥ ì¤‘ìš”)
                    price_selectors = [
                        '[class*="price"]', '[class*="fare"]', '[class*="cost"]',
                        '[class*="amount"]', '.price', '.fare', '[class*="won"]'
                    ]
                    price = "ì •ë³´ì—†ìŒ"
                    for selector in price_selectors:
                        try:
                            price_elem = await item.query_selector(selector)
                            if price_elem:
                                text = await price_elem.inner_text()
                                if text and ('ì›' in text or ',' in text or text.isdigit()):
                                    price = text.strip()
                                    break
                        except:
                            continue
                    
                    # ì‹œê°„ ì •ë³´ ì¶”ì¶œ
                    time_selectors = [
                        '[class*="time"]', '[class*="departure"]', '[class*="arrival"]',
                        '[class*="schedule"]', '.time', '.schedule'
                    ]
                    times = []
                    for selector in time_selectors:
                        try:
                            time_elems = await item.query_selector_all(selector)
                            for elem in time_elems[:2]:  # ì¶œë°œ/ë„ì°© ì‹œê°„ë§Œ
                                text = await elem.inner_text()
                                if text and ':' in text:
                                    times.append(text.strip())
                        except:
                            continue
                    
                    dept_time = times[0] if len(times) > 0 else "ì •ë³´ì—†ìŒ"
                    arr_time = times[1] if len(times) > 1 else "ì •ë³´ì—†ìŒ"
                    
                    # ì†Œìš”ì‹œê°„ ì¶”ì¶œ
                    duration_selectors = [
                        '[class*="duration"]', '[class*="flight-time"]', '[class*="time"]:contains("ì‹œê°„")',
                        '[class*="elapsed"]'
                    ]
                    duration = "ì •ë³´ì—†ìŒ"
                    for selector in duration_selectors:
                        try:
                            duration_elem = await item.query_selector(selector)
                            if duration_elem:
                                text = await duration_elem.inner_text()
                                if text and ('ì‹œê°„' in text or 'h' in text):
                                    duration = text.strip()
                                    break
                        except:
                            continue
                    
                    # ë°ì´í„°ê°€ ìœ íš¨í•œ ê²½ìš°ì—ë§Œ ì¶”ê°€
                    if price != "ì •ë³´ì—†ìŒ" or airline != "ì •ë³´ì—†ìŒ":
                        flights.append({
                            'airline': airline,
                            'price': price,
                            'departure_time': dept_time,
                            'arrival_time': arr_time,
                            'duration': duration,
                            'search_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        })
                        print(f"  í•­ê³µí¸ {i+1}: {airline} - {price}")
                    
                except Exception as e:
                    print(f"í•­ëª© {i+1} ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            print(f"ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        print(f"ì´ {len(flights)}ê°œì˜ í•­ê³µí¸ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        return flights
    
    async def crawl_all_countries(self):
        """ëª¨ë“  êµ­ê°€ì˜ í•­ê³µë£Œ ì •ë³´ ìˆ˜ì§‘"""
        all_results = {}
        
        await self.setup_browser()
        
        try:
            for country, airports in self.countries.items():
                print(f"\n=== {country.upper()} ê²€ìƒ‰ ì¤‘ ===")
                all_results[country] = {}
                
                for airport in airports:
                    try:
                        print(f"  {self.airport_cities.get(airport, airport)} ({airport}) ê²€ìƒ‰...")
                        
                        # ê° ê³µí•­ë³„ ê²€ìƒ‰
                        flights = await self.search_flights(departure='ICN', arrival=airport)
                        
                        if flights:
                            all_results[country][airport] = {
                                'city': self.airport_cities.get(airport, airport),
                                'flights': flights,
                                'min_price': min([self.extract_price(f['price']) for f in flights if self.extract_price(f['price']) > 0], default=0)
                            }
                            print(f"    ê²°ê³¼: {len(flights)}ê°œ í•­ê³µí¸, ìµœì €ê°€: {all_results[country][airport]['min_price']:,}ì›")
                        else:
                            print(f"    ê²°ê³¼ ì—†ìŒ")
                            
                        # ë‹¤ìŒ ê²€ìƒ‰ì„ ìœ„í•œ ëŒ€ê¸°
                        await self.page.wait_for_timeout(3000)
                        
                    except Exception as e:
                        print(f"  {airport} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                        continue
                        
        finally:
            await self.close_browser()
            
        return all_results
    
    def extract_price(self, price_str):
        """ê°€ê²© ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ"""
        try:
            import re
            price_num = re.sub(r'[^\d]', '', price_str)
            return int(price_num) if price_num else 0
        except:
            return 0

    def print_summary(self, results):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ë„¤ì´ë²„ í•­ê³µë£Œ í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        
        for country, airports in results.items():
            if airports:
                print(f"\nã€ {country.upper()} ã€‘")
                for airport, data in airports.items():
                    if 'min_price' in data and data['min_price'] > 0:
                        print(f"  {data['city']} ({airport}): {data['min_price']:,}ì›~")

# ì‹¤í–‰ í•¨ìˆ˜
async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    crawler = NaverFlightCrawler()
    
    print("ğŸ›« ë„¤ì´ë²„ í•­ê³µë£Œ ì‹¤ì‹œê°„ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ğŸ“ ëŒ€ìƒ êµ­ê°€: italy, japan, singapore, uk, australia, austria, canada, america, china, france, germany, newzealand")
    print("â±ï¸  ì˜ˆìƒ ì†Œìš”ì‹œê°„: ì•½ 30-60ë¶„ (ë„¤íŠ¸ì›Œí¬ ìƒí™©ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    print("-" * 70)
    
    # ëª¨ë“  êµ­ê°€ í¬ë¡¤ë§ ì‹¤í–‰
    results = await crawler.crawl_all_countries()
    
    # ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
    crawler.print_summary(results)
    
    print("\nâœ… í¬ë¡¤ë§ ì™„ë£Œ!")
    print("ğŸ“ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤ (JSON, Excel)")


# ë‹¨ì¼ êµ­ê°€ í¬ë¡¤ë§ ì˜ˆì œ (ë” ì•ˆì •ì )
async def crawl_single_country(country='japan'):
    """íŠ¹ì • êµ­ê°€ë§Œ í¬ë¡¤ë§í•˜ëŠ” ì˜ˆì œ"""
    crawler = NaverFlightCrawler()
    await crawler.setup_browser()
    
    try:
        airports = crawler.countries.get(country, [])
        results = {}
        
        for airport in airports:
            print(f"ê²€ìƒ‰ ì¤‘: {crawler.airport_cities.get(airport, airport)} ({airport})")
            flights = await crawler.search_flights(arrival=airport)
            if flights:
                results[airport] = {
                    'city': crawler.airport_cities.get(airport, airport),
                    'flights': flights,
                    'min_price': min([crawler.extract_price(f['price']) for f in flights])
                }
                print(f"ì™„ë£Œ: {len(flights)}ê°œ í•­ê³µí¸ ë°œê²¬")
            else:
                print("ê²°ê³¼ ì—†ìŒ")
            
            # ëŒ€ê¸°ì‹œê°„
            await asyncio.sleep(3)
                
        return results
    finally:
        await crawler.close_browser()

# ì‹¤ì‹œê°„ ê°€ê²© ëª¨ë‹ˆí„°ë§ ì˜ˆì œ (ê°œì„ ëœ ë²„ì „)
async def monitor_prices(target_airports=['NRT', 'SIN'], interval_minutes=30):
    """ì§€ì •ëœ ê³µí•­ë“¤ì˜ ê°€ê²©ì„ ì£¼ê¸°ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§"""
    crawler = NaverFlightCrawler()
    
    while True:
        print(f"\n{'='*50}")
        print(f"ê°€ê²© ì²´í¬ ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*50}")
        
        await crawler.setup_browser()
        try:
            for airport in target_airports:
                try:
                    city = crawler.airport_cities.get(airport, airport)
                    print(f"\nê²€ìƒ‰ ì¤‘: {city} ({airport})")
                    
                    flights = await crawler.search_flights(arrival=airport)
                    if flights:
                        prices = [crawler.extract_price(f['price']) for f in flights if crawler.extract_price(f['price']) > 0]
                        if prices:
                            min_price = min(prices)
                            avg_price = sum(prices) // len(prices)
                            print(f"  ìµœì €ê°€: {min_price:,}ì›")
                            print(f"  í‰ê· ê°€: {avg_price:,}ì›")
                            print(f"  í•­ê³µí¸: {len(flights)}ê°œ")
                        else:
                            print("  ê°€ê²© ì •ë³´ ì—†ìŒ")
                    else:
                        print("  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                        
                    await asyncio.sleep(5)  # ë‹¤ìŒ ê²€ìƒ‰ ì „ ëŒ€ê¸°
                    
                except Exception as e:
                    print(f"  ì˜¤ë¥˜: {e}")
                    continue
                    
        except Exception as e:
            print(f"ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜: {e}")
        finally:
            await crawler.close_browser()
            
        print(f"\në‹¤ìŒ ì²´í¬ê¹Œì§€ {interval_minutes}ë¶„ ëŒ€ê¸°...")
        await asyncio.sleep(interval_minutes * 60)

# íŠ¹ì • ëª©ì ì§€ ìµœì €ê°€ ì°¾ê¸°
async def find_cheapest_destination(countries=['japan', 'singapore', 'thailand']):
    """ì—¬ëŸ¬ êµ­ê°€ ì¤‘ ê°€ì¥ ì €ë ´í•œ ëª©ì ì§€ ì°¾ê¸°"""
    crawler = NaverFlightCrawler()
    await crawler.setup_browser()
    
    all_prices = []
    
    try:
        for country in countries:
            airports = crawler.countries.get(country, [])
            for airport in airports:
                try:
                    flights = await crawler.search_flights(arrival=airport)
                    if flights:
                        prices = [crawler.extract_price(f['price']) for f in flights if crawler.extract_price(f['price']) > 0]
                        if prices:
                            min_price = min(prices)
                            all_prices.append({
                                'country': country,
                                'airport': airport,
                                'city': crawler.airport_cities.get(airport, airport),
                                'min_price': min_price
                            })
                    await asyncio.sleep(3)
                except Exception as e:
                    print(f"{airport} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    
        # ê°€ê²©ìˆœ ì •ë ¬
        all_prices.sort(key=lambda x: x['min_price'])
        
        print("\nğŸ† ìµœì €ê°€ ìˆœìœ„:")
        for i, dest in enumerate(all_prices[:10], 1):
            print(f"{i:2d}. {dest['city']} ({dest['airport']}) - {dest['min_price']:,}ì›")
            
        return all_prices
        
    finally:
        await crawler.close_browser()
        
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë°©ë²•
if __name__ == "__main__":
    print("ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜:")
    print("   pip install playwright pandas openpyxl")
    print("   playwright install")
    print()
    print("ğŸš€ í¬ë¡¤ë§ ì‹œì‘...")
    print()
    
    # ì‹¤í–‰
    # asyncio.run(main())
    asyncio.run(crawl_single_country())
